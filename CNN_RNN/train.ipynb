{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a948d01-0055-463a-b611-2bd07b39cfc3",
   "metadata": {},
   "source": [
    "# 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31cf6f6-80ab-48c3-beca-bef148e0ae40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"./data/train_data.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845a80b-ec15-452c-9303-206707b39fcb",
   "metadata": {},
   "source": [
    "# 统计词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bbf8af-74d5-4310-92ed-68ab58269247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "def set_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e5694a-1923-4e47-a45d-ce70f64ce2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import count\n",
    "\n",
    "class IMCP_Vocab():\n",
    "  def __init__(self, texts) -> None:\n",
    "    words = list(itertools.chain(*[text.split(\" \") for text in texts]))\n",
    "    counter = Counter(words)\n",
    "    self.vocab = {key: i for i, key in zip(count(start = 4), counter.keys())}\n",
    "    self.special_ids = [0, 1, 2, 3]\n",
    "    self.max_seq_len = 256\n",
    "    self.counter = counter\n",
    "    self.special_tokens = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "    for id, token in zip(self.special_ids, self.special_tokens):\n",
    "      self.vocab[token] = id\n",
    "    self.vocab = {k: v for k, v in sorted(self.vocab.items(), key=lambda x:x[1])}\n",
    "    self.id2word = {v: k for k, v in self.vocab.items()}\n",
    "    \n",
    "    self.bos_token = \"<bos>\"\n",
    "    self.eos_token = \"<eos>\"\n",
    "    self.pad_token = \"<pad>\"\n",
    "    self.unk_token = \"<unk>\"\n",
    "    \n",
    "  def get_vocab(self):\n",
    "    return self.vocab\n",
    "\n",
    "  def get_vocab_dump(self):\n",
    "    vocab = dict()\n",
    "    vocab['itos'] = list(vocab.keys())\n",
    "    vocab['stoi'] = self.vocab\n",
    "    vocab['freqs'] = dict(self.counter)\n",
    "    return vocab\n",
    "  \n",
    "  def batch_decode(self, predictions_ids):\n",
    "    preds = []\n",
    "    for seq in predictions_ids:\n",
    "        preds.append(\" \".join([self.id2word[id] for id in seq if id not in [0,1,2,3,4,5]]))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c45ec-d47c-4849-a926-0cad74a1c3d0",
   "metadata": {},
   "source": [
    "# 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42647ee8-bab8-4e52-b78b-58e719dfab7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "class IMCP_Dataset(Dataset):\n",
    "  def __init__(self, image_path = \"./data/Train/\", summary_path = \"./data/train_data.json\", train = True):\n",
    "    super().__init__()\n",
    "    self.data = json.load(open(summary_path, \"r\"))\n",
    "    self.image_path = image_path\n",
    "    self.vocab = IMCP_Vocab(texts = [ann['segment_caption'] for ann in data['annotations']])\n",
    "    self.imgid2imgname = {entry['id']: entry['filename'] for entry in data['images']}\n",
    "    self.train = train\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data['annotations'])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    if self.train:\n",
    "      annotation = self.data['annotations'][index]\n",
    "      image_id = annotation['image_id']\n",
    "      # images = self.data['images'][index]\n",
    "      # image_id = images['id']\n",
    "      image_name = self.imgid2imgname[image_id]\n",
    "      image = Image.open(os.path.join(self.image_path, image_name)).convert('RGB')\n",
    "      caption = annotation['segment_caption']\n",
    "      return image, caption\n",
    "    else:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23310c65-3cb8-4b92-bb48-b09b99cf4e3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ddd4a8-22c1-48ea-b68d-07c1d6e5539d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class IMCP_Collator:\n",
    "  def __init__(self, vocab, train = True):\n",
    "    self.vocab = vocab\n",
    "    self.bos_id = self.vocab.get_vocab()['<bos>']\n",
    "    self.eos_id = self.vocab.get_vocab()['<eos>']\n",
    "    self.pad_id = self.vocab.get_vocab()['<pad>']\n",
    "\n",
    "  def tokenize_texts(self, captions):\n",
    "    raw_captions = [caption.split(\" \") for caption in captions]\n",
    "    truncated_captions = [s[:self.vocab.max_seq_len] for s in raw_captions]\n",
    "    max_len = max([len(c) for c in truncated_captions])\n",
    "\n",
    "    padded_captions = []\n",
    "    for c in truncated_captions:\n",
    "        c = [self.vocab.get_vocab()[word] for word in c]\n",
    "        seq = [self.bos_id] + c + [self.eos_id] + [self.pad_id] * (max_len - len(c))\n",
    "        padded_captions.append(seq)\n",
    "\n",
    "    padded_captions = [torch.Tensor(seq).long() for seq in padded_captions]\n",
    "    padded_captions = pad_sequence(padded_captions, batch_first=True)\n",
    "    return padded_captions\n",
    "  \n",
    "  def resize_and_stack(self, images):\n",
    "    new_size = (224, 224)\n",
    "    image_tensors = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    for image in images:\n",
    "      img_tensor = transform(image)\n",
    "      image.close()\n",
    "      image_tensors.append(img_tensor)\n",
    "      \n",
    "    stacked = torch.stack(image_tensors)\n",
    "    return stacked\n",
    "\n",
    "  def __call__(self, batch):\n",
    "    images = [example[0] for example in batch]\n",
    "    captions = [example[1] for example in batch]\n",
    "    return {\n",
    "        'images': self.resize_and_stack(images),\n",
    "        'captions': self.tokenize_texts(captions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964e6600-ec36-4332-998d-663e288cfff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_random_seed(10)\n",
    "train_dataset = IMCP_Dataset()\n",
    "vocab = train_dataset.vocab\n",
    "collator = IMCP_Collator(vocab, train = True)\n",
    "with open(\"./output/vocab.json\", 'w+') as file:\n",
    "  json.dump(vocab.get_vocab_dump(), file, ensure_ascii = False)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [0.9, 0.1])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 16, collate_fn = collator, drop_last = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = 16, collate_fn = collator, drop_last = True, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63774cb4-72b7-45c1-b7f6-b3b43f56c94d",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045aff7c-a4de-4f25-989d-bd317981fb84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch 0\n",
      "Epoch [1/20], Step [1/112], Loss: 7.3325\n",
      "Epoch [1/20], Step [11/112], Loss: 7.0451\n",
      "Epoch [1/20], Step [21/112], Loss: 5.8810\n",
      "Epoch [1/20], Step [31/112], Loss: 5.1470\n",
      "Epoch [1/20], Step [41/112], Loss: 4.7255\n",
      "Epoch [1/20], Step [51/112], Loss: 3.6516\n",
      "Epoch [1/20], Step [61/112], Loss: 3.5640\n",
      "Epoch [1/20], Step [71/112], Loss: 3.3090\n",
      "Epoch [1/20], Step [81/112], Loss: 3.3443\n",
      "Epoch [1/20], Step [91/112], Loss: 3.8757\n",
      "Epoch [1/20], Step [101/112], Loss: 2.6051\n",
      "Epoch [1/20], Step [111/112], Loss: 2.7562\n",
      "Epoch [1/20], Valid Loss: 3.1339\n",
      "Start Epoch 1\n",
      "Epoch [2/20], Step [1/112], Loss: 3.1130\n",
      "Epoch [2/20], Step [11/112], Loss: 3.4362\n",
      "Epoch [2/20], Step [21/112], Loss: 3.0930\n",
      "Epoch [2/20], Step [31/112], Loss: 3.0816\n",
      "Epoch [2/20], Step [41/112], Loss: 3.2048\n",
      "Epoch [2/20], Step [51/112], Loss: 2.6352\n",
      "Epoch [2/20], Step [61/112], Loss: 2.6379\n",
      "Epoch [2/20], Step [71/112], Loss: 2.6180\n",
      "Epoch [2/20], Step [81/112], Loss: 2.5920\n",
      "Epoch [2/20], Step [91/112], Loss: 3.1124\n",
      "Epoch [2/20], Step [101/112], Loss: 1.9190\n",
      "Epoch [2/20], Step [111/112], Loss: 2.1900\n",
      "Epoch [2/20], Valid Loss: 2.5278\n",
      "Start Epoch 2\n",
      "Epoch [3/20], Step [1/112], Loss: 2.3418\n",
      "Epoch [3/20], Step [11/112], Loss: 2.7678\n",
      "Epoch [3/20], Step [21/112], Loss: 2.4606\n",
      "Epoch [3/20], Step [31/112], Loss: 2.4573\n",
      "Epoch [3/20], Step [41/112], Loss: 2.5436\n",
      "Epoch [3/20], Step [51/112], Loss: 2.1525\n",
      "Epoch [3/20], Step [61/112], Loss: 2.1839\n",
      "Epoch [3/20], Step [71/112], Loss: 2.2539\n",
      "Epoch [3/20], Step [81/112], Loss: 2.1541\n",
      "Epoch [3/20], Step [91/112], Loss: 2.6449\n",
      "Epoch [3/20], Step [101/112], Loss: 1.5646\n",
      "Epoch [3/20], Step [111/112], Loss: 1.8621\n",
      "Epoch [3/20], Valid Loss: 2.2784\n",
      "Start Epoch 3\n",
      "Epoch [4/20], Step [1/112], Loss: 1.9684\n",
      "Epoch [4/20], Step [11/112], Loss: 2.2642\n",
      "Epoch [4/20], Step [21/112], Loss: 2.0755\n",
      "Epoch [4/20], Step [31/112], Loss: 2.0717\n",
      "Epoch [4/20], Step [41/112], Loss: 2.1374\n",
      "Epoch [4/20], Step [51/112], Loss: 1.8785\n",
      "Epoch [4/20], Step [61/112], Loss: 1.9159\n",
      "Epoch [4/20], Step [71/112], Loss: 2.0253\n",
      "Epoch [4/20], Step [81/112], Loss: 1.8708\n",
      "Epoch [4/20], Step [91/112], Loss: 2.3112\n",
      "Epoch [4/20], Step [101/112], Loss: 1.3750\n",
      "Epoch [4/20], Step [111/112], Loss: 1.6459\n",
      "Epoch [4/20], Valid Loss: 2.1492\n",
      "Start Epoch 4\n",
      "Epoch [5/20], Step [1/112], Loss: 1.7328\n",
      "Epoch [5/20], Step [11/112], Loss: 1.9896\n",
      "Epoch [5/20], Step [21/112], Loss: 1.8052\n",
      "Epoch [5/20], Step [31/112], Loss: 1.8117\n",
      "Epoch [5/20], Step [41/112], Loss: 1.8716\n",
      "Epoch [5/20], Step [51/112], Loss: 1.6951\n",
      "Epoch [5/20], Step [61/112], Loss: 1.7062\n",
      "Epoch [5/20], Step [71/112], Loss: 1.8148\n",
      "Epoch [5/20], Step [81/112], Loss: 1.7181\n",
      "Epoch [5/20], Step [91/112], Loss: 2.0666\n",
      "Epoch [5/20], Step [101/112], Loss: 1.2956\n",
      "Epoch [5/20], Step [111/112], Loss: 1.4982\n",
      "Epoch [5/20], Valid Loss: 2.0957\n",
      "Start Epoch 5\n",
      "Epoch [6/20], Step [1/112], Loss: 1.5928\n",
      "Epoch [6/20], Step [11/112], Loss: 1.7548\n",
      "Epoch [6/20], Step [21/112], Loss: 1.5943\n",
      "Epoch [6/20], Step [31/112], Loss: 1.6515\n",
      "Epoch [6/20], Step [41/112], Loss: 1.6357\n",
      "Epoch [6/20], Step [51/112], Loss: 1.5276\n",
      "Epoch [6/20], Step [61/112], Loss: 1.5208\n",
      "Epoch [6/20], Step [71/112], Loss: 1.6239\n",
      "Epoch [6/20], Step [81/112], Loss: 1.5519\n",
      "Epoch [6/20], Step [91/112], Loss: 1.8958\n",
      "Epoch [6/20], Step [101/112], Loss: 1.1937\n",
      "Epoch [6/20], Step [111/112], Loss: 1.3924\n",
      "Epoch [6/20], Valid Loss: 2.0336\n",
      "Start Epoch 6\n",
      "Epoch [7/20], Step [1/112], Loss: 1.4394\n",
      "Epoch [7/20], Step [11/112], Loss: 1.5432\n",
      "Epoch [7/20], Step [21/112], Loss: 1.4177\n",
      "Epoch [7/20], Step [31/112], Loss: 1.4837\n",
      "Epoch [7/20], Step [41/112], Loss: 1.4698\n",
      "Epoch [7/20], Step [51/112], Loss: 1.4551\n",
      "Epoch [7/20], Step [61/112], Loss: 1.4091\n",
      "Epoch [7/20], Step [71/112], Loss: 1.4976\n",
      "Epoch [7/20], Step [81/112], Loss: 1.4517\n",
      "Epoch [7/20], Step [91/112], Loss: 1.7745\n",
      "Epoch [7/20], Step [101/112], Loss: 1.1127\n",
      "Epoch [7/20], Step [111/112], Loss: 1.2573\n",
      "Epoch [7/20], Valid Loss: 2.0046\n",
      "Start Epoch 7\n",
      "Epoch [8/20], Step [1/112], Loss: 1.3043\n",
      "Epoch [8/20], Step [11/112], Loss: 1.3809\n",
      "Epoch [8/20], Step [21/112], Loss: 1.3332\n",
      "Epoch [8/20], Step [31/112], Loss: 1.3536\n",
      "Epoch [8/20], Step [41/112], Loss: 1.3803\n",
      "Epoch [8/20], Step [51/112], Loss: 1.3281\n",
      "Epoch [8/20], Step [61/112], Loss: 1.3447\n",
      "Epoch [8/20], Step [71/112], Loss: 1.3834\n",
      "Epoch [8/20], Step [81/112], Loss: 1.3341\n",
      "Epoch [8/20], Step [91/112], Loss: 1.6171\n",
      "Epoch [8/20], Step [101/112], Loss: 1.0862\n",
      "Epoch [8/20], Step [111/112], Loss: 1.1828\n",
      "Epoch [8/20], Valid Loss: 1.9750\n",
      "Start Epoch 8\n",
      "Epoch [9/20], Step [1/112], Loss: 1.2175\n",
      "Epoch [9/20], Step [11/112], Loss: 1.2282\n",
      "Epoch [9/20], Step [21/112], Loss: 1.1541\n",
      "Epoch [9/20], Step [31/112], Loss: 1.1893\n",
      "Epoch [9/20], Step [41/112], Loss: 1.2218\n",
      "Epoch [9/20], Step [51/112], Loss: 1.2159\n",
      "Epoch [9/20], Step [61/112], Loss: 1.1994\n",
      "Epoch [9/20], Step [71/112], Loss: 1.3042\n",
      "Epoch [9/20], Step [81/112], Loss: 1.1910\n",
      "Epoch [9/20], Step [91/112], Loss: 1.5335\n",
      "Epoch [9/20], Step [101/112], Loss: 0.9702\n",
      "Epoch [9/20], Step [111/112], Loss: 1.0946\n",
      "Epoch [9/20], Valid Loss: 1.9626\n",
      "Start Epoch 9\n",
      "Epoch [10/20], Step [1/112], Loss: 1.1158\n",
      "Epoch [10/20], Step [11/112], Loss: 1.1267\n",
      "Epoch [10/20], Step [21/112], Loss: 1.0780\n",
      "Epoch [10/20], Step [31/112], Loss: 1.0752\n",
      "Epoch [10/20], Step [41/112], Loss: 1.0724\n",
      "Epoch [10/20], Step [51/112], Loss: 1.1528\n",
      "Epoch [10/20], Step [61/112], Loss: 1.0769\n",
      "Epoch [10/20], Step [71/112], Loss: 1.1845\n",
      "Epoch [10/20], Step [81/112], Loss: 1.1128\n",
      "Epoch [10/20], Step [91/112], Loss: 1.3192\n",
      "Epoch [10/20], Step [101/112], Loss: 0.9135\n",
      "Epoch [10/20], Step [111/112], Loss: 1.0169\n",
      "Epoch [10/20], Valid Loss: 1.9648\n",
      "Start Epoch 10\n",
      "Epoch [11/20], Step [1/112], Loss: 1.0580\n",
      "Epoch [11/20], Step [11/112], Loss: 1.0004\n",
      "Epoch [11/20], Step [21/112], Loss: 0.9777\n",
      "Epoch [11/20], Step [31/112], Loss: 0.9730\n",
      "Epoch [11/20], Step [41/112], Loss: 0.9986\n",
      "Epoch [11/20], Step [51/112], Loss: 1.0484\n",
      "Epoch [11/20], Step [61/112], Loss: 0.9792\n",
      "Epoch [11/20], Step [71/112], Loss: 1.0797\n",
      "Epoch [11/20], Step [81/112], Loss: 0.9924\n",
      "Epoch [11/20], Step [91/112], Loss: 1.1928\n",
      "Epoch [11/20], Step [101/112], Loss: 0.8553\n",
      "Epoch [11/20], Step [111/112], Loss: 0.9013\n",
      "Epoch [11/20], Valid Loss: 1.9435\n",
      "Start Epoch 11\n",
      "Epoch [12/20], Step [1/112], Loss: 0.9300\n",
      "Epoch [12/20], Step [11/112], Loss: 0.9008\n",
      "Epoch [12/20], Step [21/112], Loss: 0.8771\n",
      "Epoch [12/20], Step [31/112], Loss: 0.9059\n",
      "Epoch [12/20], Step [41/112], Loss: 0.9224\n",
      "Epoch [12/20], Step [51/112], Loss: 0.9606\n",
      "Epoch [12/20], Step [61/112], Loss: 0.9092\n",
      "Epoch [12/20], Step [71/112], Loss: 0.9833\n",
      "Epoch [12/20], Step [81/112], Loss: 0.9358\n",
      "Epoch [12/20], Step [91/112], Loss: 1.1171\n",
      "Epoch [12/20], Step [101/112], Loss: 0.7978\n",
      "Epoch [12/20], Step [111/112], Loss: 0.8424\n",
      "Epoch [12/20], Valid Loss: 1.9349\n",
      "Start Epoch 12\n",
      "Epoch [13/20], Step [1/112], Loss: 0.8878\n",
      "Epoch [13/20], Step [11/112], Loss: 0.8050\n",
      "Epoch [13/20], Step [21/112], Loss: 0.7719\n",
      "Epoch [13/20], Step [31/112], Loss: 0.8046\n",
      "Epoch [13/20], Step [41/112], Loss: 0.8359\n",
      "Epoch [13/20], Step [51/112], Loss: 0.8895\n",
      "Epoch [13/20], Step [61/112], Loss: 0.8533\n",
      "Epoch [13/20], Step [71/112], Loss: 0.8851\n",
      "Epoch [13/20], Step [81/112], Loss: 0.8669\n",
      "Epoch [13/20], Step [91/112], Loss: 1.0586\n",
      "Epoch [13/20], Step [101/112], Loss: 0.7527\n",
      "Epoch [13/20], Step [111/112], Loss: 0.7690\n",
      "Epoch [13/20], Valid Loss: 1.9395\n",
      "Start Epoch 13\n",
      "Epoch [14/20], Step [1/112], Loss: 0.8267\n",
      "Epoch [14/20], Step [11/112], Loss: 0.7910\n",
      "Epoch [14/20], Step [21/112], Loss: 0.7118\n",
      "Epoch [14/20], Step [31/112], Loss: 0.7622\n",
      "Epoch [14/20], Step [41/112], Loss: 0.7882\n",
      "Epoch [14/20], Step [51/112], Loss: 0.8263\n",
      "Epoch [14/20], Step [61/112], Loss: 0.8086\n",
      "Epoch [14/20], Step [71/112], Loss: 0.8442\n",
      "Epoch [14/20], Step [81/112], Loss: 0.7821\n",
      "Epoch [14/20], Step [91/112], Loss: 0.9607\n",
      "Epoch [14/20], Step [101/112], Loss: 0.7104\n",
      "Epoch [14/20], Step [111/112], Loss: 0.7405\n",
      "Epoch [14/20], Valid Loss: 1.9247\n",
      "Start Epoch 14\n",
      "Epoch [15/20], Step [1/112], Loss: 0.7559\n",
      "Epoch [15/20], Step [11/112], Loss: 0.7110\n",
      "Epoch [15/20], Step [21/112], Loss: 0.6598\n",
      "Epoch [15/20], Step [31/112], Loss: 0.7298\n",
      "Epoch [15/20], Step [41/112], Loss: 0.7248\n",
      "Epoch [15/20], Step [51/112], Loss: 0.7663\n",
      "Epoch [15/20], Step [61/112], Loss: 0.7719\n",
      "Epoch [15/20], Step [71/112], Loss: 0.7847\n",
      "Epoch [15/20], Step [81/112], Loss: 0.7419\n",
      "Epoch [15/20], Step [91/112], Loss: 0.8918\n",
      "Epoch [15/20], Step [101/112], Loss: 0.6831\n",
      "Epoch [15/20], Step [111/112], Loss: 0.7022\n",
      "Epoch [15/20], Valid Loss: 1.9166\n",
      "Start Epoch 15\n",
      "Epoch [16/20], Step [1/112], Loss: 0.7114\n",
      "Epoch [16/20], Step [11/112], Loss: 0.6715\n",
      "Epoch [16/20], Step [21/112], Loss: 0.6194\n",
      "Epoch [16/20], Step [31/112], Loss: 0.6786\n",
      "Epoch [16/20], Step [41/112], Loss: 0.6818\n",
      "Epoch [16/20], Step [51/112], Loss: 0.7403\n",
      "Epoch [16/20], Step [61/112], Loss: 0.7281\n",
      "Epoch [16/20], Step [71/112], Loss: 0.7597\n",
      "Epoch [16/20], Step [81/112], Loss: 0.7385\n",
      "Epoch [16/20], Step [91/112], Loss: 0.8616\n",
      "Epoch [16/20], Step [101/112], Loss: 0.6618\n",
      "Epoch [16/20], Step [111/112], Loss: 0.6712\n",
      "Epoch [16/20], Valid Loss: 1.9112\n",
      "Start Epoch 16\n",
      "Epoch [17/20], Step [1/112], Loss: 0.6924\n",
      "Epoch [17/20], Step [11/112], Loss: 0.6537\n",
      "Epoch [17/20], Step [21/112], Loss: 0.6050\n",
      "Epoch [17/20], Step [31/112], Loss: 0.6412\n",
      "Epoch [17/20], Step [41/112], Loss: 0.6763\n",
      "Epoch [17/20], Step [51/112], Loss: 0.7171\n",
      "Epoch [17/20], Step [61/112], Loss: 0.7024\n",
      "Epoch [17/20], Step [71/112], Loss: 0.7412\n",
      "Epoch [17/20], Step [81/112], Loss: 0.7223\n",
      "Epoch [17/20], Step [91/112], Loss: 0.8251\n",
      "Epoch [17/20], Step [101/112], Loss: 0.6442\n",
      "Epoch [17/20], Step [111/112], Loss: 0.6363\n",
      "Epoch [17/20], Valid Loss: 1.8999\n",
      "Start Epoch 17\n",
      "Epoch [18/20], Step [1/112], Loss: 0.6732\n",
      "Epoch [18/20], Step [11/112], Loss: 0.6194\n",
      "Epoch [18/20], Step [21/112], Loss: 0.5803\n",
      "Epoch [18/20], Step [31/112], Loss: 0.6209\n",
      "Epoch [18/20], Step [41/112], Loss: 0.6581\n",
      "Epoch [18/20], Step [51/112], Loss: 0.6890\n",
      "Epoch [18/20], Step [61/112], Loss: 0.6827\n",
      "Epoch [18/20], Step [71/112], Loss: 0.7165\n",
      "Epoch [18/20], Step [81/112], Loss: 0.6791\n",
      "Epoch [18/20], Step [91/112], Loss: 0.7849\n",
      "Epoch [18/20], Step [101/112], Loss: 0.6256\n",
      "Epoch [18/20], Step [111/112], Loss: 0.6170\n",
      "Epoch [18/20], Valid Loss: 1.8917\n",
      "Start Epoch 18\n",
      "Epoch [19/20], Step [1/112], Loss: 0.6604\n",
      "Epoch [19/20], Step [11/112], Loss: 0.5954\n",
      "Epoch [19/20], Step [21/112], Loss: 0.5391\n",
      "Epoch [19/20], Step [31/112], Loss: 0.5925\n",
      "Epoch [19/20], Step [41/112], Loss: 0.6310\n",
      "Epoch [19/20], Step [51/112], Loss: 0.6626\n",
      "Epoch [19/20], Step [61/112], Loss: 0.6488\n",
      "Epoch [19/20], Step [71/112], Loss: 0.6777\n",
      "Epoch [19/20], Step [81/112], Loss: 0.6542\n",
      "Epoch [19/20], Step [91/112], Loss: 0.7505\n",
      "Epoch [19/20], Step [101/112], Loss: 0.6012\n",
      "Epoch [19/20], Step [111/112], Loss: 0.5966\n",
      "Epoch [19/20], Valid Loss: 1.8863\n",
      "Start Epoch 19\n",
      "Epoch [20/20], Step [1/112], Loss: 0.6398\n",
      "Epoch [20/20], Step [11/112], Loss: 0.5698\n",
      "Epoch [20/20], Step [21/112], Loss: 0.5199\n",
      "Epoch [20/20], Step [31/112], Loss: 0.5713\n",
      "Epoch [20/20], Step [41/112], Loss: 0.6054\n",
      "Epoch [20/20], Step [51/112], Loss: 0.6462\n",
      "Epoch [20/20], Step [61/112], Loss: 0.6322\n",
      "Epoch [20/20], Step [71/112], Loss: 0.6610\n",
      "Epoch [20/20], Step [81/112], Loss: 0.6416\n",
      "Epoch [20/20], Step [91/112], Loss: 0.7407\n",
      "Epoch [20/20], Step [101/112], Loss: 0.5941\n",
      "Epoch [20/20], Step [111/112], Loss: 0.5903\n",
      "Epoch [20/20], Valid Loss: 1.8859\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from transformers import get_scheduler, get_cosine_schedule_with_warmup\n",
    "\n",
    "# 确定GPU是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载预训练ResNet101模型\n",
    "encoder = models.resnet101(pretrained=True).to(device)\n",
    "\n",
    "# 去除模型的最后一层\n",
    "modules = list(encoder.children())[:-1]\n",
    "encoder = nn.Sequential(*modules)\n",
    "\n",
    "# 冻结模型参数\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 定义LSTM解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, feature_size, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size + feature_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, features, captions):\n",
    "        captions = captions[:, :-1]\n",
    "        embeddings = self.embed(captions)\n",
    "        features = features.squeeze().unsqueeze(1).repeat(1, embeddings.size(1), 1)\n",
    "        embeddings = torch.cat((features, embeddings), 2)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs\n",
    "\n",
    "# 定义超参数\n",
    "num_epochs = 20\n",
    "embed_size = 256\n",
    "feature_size = 2048\n",
    "hidden_size = 512\n",
    "vocab_size = len(collator.vocab.get_vocab()) + 5\n",
    "num_layers = 1\n",
    "total_step = num_epochs * len(train_dataloader)\n",
    "\n",
    "\n",
    "# 初始化解码器\n",
    "decoder = Decoder(feature_size, embed_size, hidden_size, vocab_size, num_layers).to(device)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化率和学习率更新策略\n",
    "param_optimizer = list(decoder.parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer = torch.optim.AdamW(param_optimizer, lr=0.001, weight_decay=0.001)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = 0.1 * total_step, num_training_steps = total_step)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Start Epoch {epoch}\")\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # 将数据移到GPU\n",
    "        images = data['images'].to(device)\n",
    "        captions = data['captions'].to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        loss = criterion(outputs.permute(0, 2, 1), captions[:, 1:])\n",
    "        \n",
    "        # 反向传播并优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # 输出损失\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n",
    "            \n",
    "    valid_loss = []\n",
    "    for i, data in enumerate(valid_dataloader):\n",
    "        # 将数据移到GPU\n",
    "        images = data['images'].to(device)\n",
    "        captions = data['captions'].to(device)\n",
    "        # 前向传播\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        loss = criterion(outputs.permute(0, 2, 1), captions[:, 1:])\n",
    "        valid_loss.append(loss.item())\n",
    "    \n",
    "    print('Epoch [{}/{}], Valid Loss: {:.4f}'.format(epoch+1, num_epochs, np.mean(valid_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52d8da-19db-4155-83fc-6c8774116e3e",
   "metadata": {},
   "source": [
    "# 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456a5000-4c59-44b3-a357-a473ee11857a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './output/encoder.pth')\n",
    "torch.save(decoder.state_dict(), './output/decoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
